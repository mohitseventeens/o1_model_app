
    <html>
    <head>
        <meta charset="UTF-8">
        <title>O1 Response</title>
        <!-- Add MathJax for LaTeX rendering -->
        <script type="text/javascript" async 
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    </head>
    <body>
    <head>
        <meta charset="UTF-8">
        <title>O1 Response</title>
    </head>
    <body>
        <!--
        <h2>System Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            <br>- You are an expert Python programmer and refactoring specialist.<br>- Before refactoring you need to Identify flaws in logic, inefficiencies, potential bugs and correct those.<br>- Your task is to refactor the provided Python code step by step, convert the code into object-oriented approach.<br>- Provide the following for each step:<br>  - A brief explanation of what is being refactored and why the change is necessary.<br>  - The original code snippet and the refactored version, presented side by side using Python code blocks.<br>  - Highlight the improvements in the refactored version, such as enhanced readability, better performance, or bug fixes.<br>- If additional functionality or changes in design are needed (e.g., converting the code to an object-oriented approach or refactoring for async programming), explain the rationale before implementing.<br>- Structure the output using HTML elements.<br>  - blocks for Python code and ensure proper syntax highlighting.<br>  - Highlight improvements or key points using colors or styling with inline CSS or styled `<div>` blocks.<br>- Ensure the tone is professional, constructive, and educational.<br>- Keep the layout clean and intuitive, ensuring the user can easily follow the suggestions and apply them effectively.<br>
        </div>

        <h2>User Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            <br>import warnings<br>import time<br>from IPython.display import display, Markdown, HTML<br>from helper import get_openai_api_key<br>from openai import OpenAI<br><br>import markdown<br><br>def o1_response(prompt, system_prompt, o1_model="o1", display=False, file_name="o1_response_test.html"):<br>    """<br>    Generate a response using the O1 model.<br><br>    Args:<br>        prompt (str): The user prompt.<br>        system_prompt (str): The system prompt.<br><br>    Returns:<br>        None: Displays the response and response time.<br>    """<br>    # Suppress warnings<br>    warnings.filterwarnings('ignore')<br><br>    openai_api_key = get_openai_api_key()<br>    client = OpenAI(api_key=openai_api_key)<br><br><br>    # Record the start time<br>    start_time = time.time()<br><br>    # Generate the response<br>    response = client.chat.completions.create(<br>        model=o1_model,<br>        messages=[{<br>            "role": "user",<br>            "content": f"<System Prompt>{system_prompt}</System Prompt> <br> <USER Prompt>{prompt}</USER Prompt>"<br>        }]<br>    )<br><br>    # Measure response time<br>    end_time = time.time()<br>    response_time = end_time - start_time<br>    <br>    # Measure cost for o1, o1-mini    <br>    if o1_model == "o1":<br>        input_token_price = 15.00 / 1000000<br>        cached_input_token_price = 7.50 / 1000000<br>        output_token_price = 60.00 / 1000000<br>    elif o1_model == "o1-mini":<br>        input_token_price = 3.00 / 1000000<br>        cached_input_token_price = 1.50 / 1000000<br>        output_token_price = 12.00 / 1000000<br>        <br>    prompt_tokens = response.usage.prompt_tokens<br>    cached_input_tokens = response.usage.prompt_tokens_details.cached_tokens<br>    output_tokens = response.usage.completion_tokens<br>    <br>    # Individual cost<br>    input_token_cost = (prompt_tokens - cached_input_tokens) * input_token_price<br>    cached_input_token_cost = cached_input_tokens * cached_input_token_price<br>    output_token_cost = output_tokens * output_token_price<br>    <br>    total_cost = input_token_cost + cached_input_token_cost + output_token_cost<br><br>    <br>    # response_content<br>    response_content = response.choices[0].message.content<br><br>    if display:<br>        # Display the time taken for the response<br>        display(HTML(f'<div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">                <h2>ðŸ”½ &nbsp; O1 Model Response</h2><p>Response time: {response_time:.2f} seconds</p></div>'))<br><br>        # Display the response in a formatted way<br>        display(Markdown(response_content))<br>        display(HTML('<div style="background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">                <h2>ðŸ”¼ &nbsp; Markdown End</h2></div>'))<br><br>    <br>    # convert prompts into html<br>    system_prompt_html = system_prompt.replace('<br>', '<br>')<br>    prompt_html = prompt.replace('<br>', '<br>')<br><br>    <br>    # result<br>    result = {"content": response_content, "time": response_time}<br>    <br>    # Extract the content and format it as HTML<br>    response_html = markdown.markdown(result['content'])<br>    <br>    <br>    # Format the response as HTML<br>    html_content = f"""<br>    <html><br>    <head><br>        <meta charset="UTF-8"><br>        <title>O1 Response</title><br>        <!-- Add MathJax for LaTeX rendering --><br>        <script type="text/javascript" async <br>            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"><br>        </script><br>    </head><br>    <body><br>    <head><br>        <meta charset="UTF-8"><br>        <title>O1 Response</title><br>    </head><br>    <body><br>        <!--<br>        <h2>System Prompt</h2><br>        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;"><br>            {system_prompt_html}<br>        </div><br><br>        <h2>User Prompt</h2><br>        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;"><br>            {prompt_html}<br>        </div><br><br>        <br><br>  <!-- Blank space between prompts and response --><br>        <div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;"><br>            <h2>{o1_model} Model Response</h2><br>            <p>Response time: {result['time']:.2f} seconds</p><br>            <p>Total Cost: {total_cost:.2f} $</p><br>        </div><br><br>        <div style="padding: 10px;"><br>            {response_html}<br>        </div><br>    </body><br>    </html><br>    """<br><br>    # Save the HTML content to a file<br>    with open(file_name, "w", encoding="utf-8") as file:<br>        file.write(html_content)<br><br>    print(f"Response saved to {file_name}")<br>    <br>    return response<br>
        </div>

        <br><br>  <!-- Blank space between prompts and response -->
        <div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
            <h2>o1-mini Model Response</h2>
            <p>Response time: 57.32 seconds</p>
            <p>Total Cost: 0.10 $</p>
        </div>

        <div style="padding: 10px;">
            <p>```html</p>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Refactoring Python Code: Procedural to Object-Oriented</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
        }
        .step {
            margin-bottom: 40px;
        }
        .step-header {
            background-color: #f2f2f2;
            padding: 10px;
            border-left: 5px solid #4CAF50;
            margin-bottom: 10px;
        }
        .explanation {
            margin-bottom: 10px;
        }
        .code-container {
            display: flex;
            gap: 20px;
            margin-bottom: 10px;
        }
        .code-block {
            width: 48%;
        }
        pre {
            background-color: #272822;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }
        .highlight {
            background-color: #ffffcc;
            padding: 2px 4px;
            border-radius: 3px;
        }
        .improvement {
            color: #2E8B57;
            font-weight: bold;
        }
    </style>
</head>
<body>

    <h1>Refactoring Python Code: Procedural to Object-Oriented</h1>

    <div class="step">
        <div class="step-header">
            <h2>Step 1: Identifying Responsibilities and Preparing for OOP Conversion</h2>
        </div>
        <div class="explanation">
            In this initial step, we analyze the existing procedural code to identify distinct responsibilities. This helps in determining how to structure classes and methods effectively in an object-oriented design.
        </div>
        <div class="code-container">
            <div class="code-block">
                <h3>Original Code</h3>
                <pre><code class="python">import warnings
import time
from IPython.display import display, Markdown, HTML
from helper import get_openai_api_key
from openai import OpenAI

import markdown

def o1_response(prompt, system_prompt, o1_model="o1", display=False, file_name="o1_response_test.html"):
    """
    Generate a response using the O1 model.

    Args:
        prompt (str): The user prompt.
        system_prompt (str): The system prompt.

    Returns:
        None: Displays the response and response time.
    """
    # Suppress warnings
    warnings.filterwarnings('ignore')

    openai_api_key = get_openai_api_key()
    client = OpenAI(api_key=openai_api_key)

    # Record the start time
    start_time = time.time()

    # Generate the response
    response = client.chat.completions.create(
        model=o1_model,
        messages=[{
            "role": "user",
            "content": f"<System Prompt>{system_prompt}</System Prompt> 
 <USER Prompt>{prompt}</USER Prompt>"
        }]
    )

    # Measure response time
    end_time = time.time()
    response_time = end_time - start_time

    # Measure cost for o1, o1-mini    
    if o1_model == "o1":
        input_token_price = 15.00 / 1000000
        cached_input_token_price = 7.50 / 1000000
        output_token_price = 60.00 / 1000000
    elif o1_model == "o1-mini":
        input_token_price = 3.00 / 1000000
        cached_input_token_price = 1.50 / 1000000
        output_token_price = 12.00 / 1000000

    prompt_tokens = response.usage.prompt_tokens
    cached_input_tokens = response.usage.prompt_tokens_details.cached_tokens
    output_tokens = response.usage.completion_tokens

    # Individual cost
    input_token_cost = (prompt_tokens - cached_input_tokens) * input_token_price
    cached_input_token_cost = cached_input_tokens * cached_input_token_price
    output_token_cost = output_tokens * output_token_price

    total_cost = input_token_cost + cached_input_token_cost + output_token_cost


    # response_content
    response_content = response.choices[0].message.content

    if display:
        # Display the time taken for the response
        display(HTML(f'<div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">                <h2>ðŸ”½ &nbsp; O1 Model Response</h2><p>Response time: {response_time:.2f} seconds</p></div>'))

        # Display the response in a formatted way
        display(Markdown(response_content))
        display(HTML('<div style="background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">                <h2>ðŸ”¼ &nbsp; Markdown End</h2></div>'))


    # convert prompts into html
    system_prompt_html = system_prompt.replace('
', '<br>')
    prompt_html = prompt.replace('
', '<br>')


    # result
    result = {"content": response_content, "time": response_time}

    # Extract the content and format it as HTML
    response_html = markdown.markdown(result['content'])


    # Format the response as HTML
    html_content = f"""
    <html>
    <head>
        <meta charset="UTF-8">
        <title>O1 Response</title>
        <!-- Add MathJax for LaTeX rendering -->
        <script type="text/javascript" async 
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    </head>
    <body>
    <head>
        <meta charset="UTF-8">
        <title>O1 Response</title>
    </head>
    <body>
        <!--
        <h2>System Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            {system_prompt_html}
        </div>

        <h2>User Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            {prompt_html}
        </div>

        <br><br>  <!-- Blank space between prompts and response -->
        <div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
            <h2>{o1_model} Model Response</h2>
            <p>Response time: {result['time']:.2f} seconds</p>
            <p>Total Cost: {total_cost:.2f} $</p>
        </div>

        <div style="padding: 10px;">
            {response_html}
        </div>
    </body>
    </html>
    """

    # Save the HTML content to a file
    with open(file_name, "w", encoding="utf-8") as file:
        file.write(html_content)

    print(f"Response saved to {file_name}")

    return response
</code></pre>
            </div>
            <div class="code-block">
                <h3>Refactored Code</h3>
                <pre><code class="python"># Initial analysis completed. No refactored code at this step.</code></pre>
            </div>
        </div>
        <div class="improvement">
            ðŸŽ¯ <span>Improvement:</span> Understanding the current functionality to strategize effective object-oriented design.
        </div>
    </div>

    <div class="step">
        <div class="step-header">
            <h2>Step 2: Creating the OpenAI Client Wrapper</h2>
        </div>
        <div class="explanation">
            To adhere to the Single Responsibility Principle, we encapsulate the OpenAI client interactions within a dedicated class. This separation allows for easier maintenance and potential extensions in the future.
        </div>
        <div class="code-container">
            <div class="code-block">
                <h3>Original Code Snippet</h3>
                <pre><code class="python">openai_api_key = get_openai_api_key()
client = OpenAI(api_key=openai_api_key)

# Generate the response
response = client.chat.completions.create(
    model=o1_model,
    messages=[{
        "role": "user",
        "content": f"&lt;System Prompt&gt;{system_prompt}&lt;/System Prompt&gt; 
&lt;USER Prompt&gt;{prompt}&lt;/USER Prompt&gt;"
    }]
)</code></pre>
            </div>
            <div class="code-block">
                <h3>Refactored Code Snippet</h3>
                <pre><code class="python">class OpenAIClient:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def generate_response(self, model: str, system_prompt: str, user_prompt: str):
        message = {
            "role": "user",
            "content": f"&lt;System Prompt&gt;{system_prompt}&lt;/System Prompt&gt;\n&lt;USER Prompt&gt;{user_prompt}&lt;/USER Prompt&gt;"
        }
        response = self.client.chat.completions.create(
            model=model,
            messages=[message]
        )
        return response

# Usage within o1_response function
openai_client = OpenAIClient(api_key=get_openai_api_key())
response = openai_client.generate_response(o1_model, system_prompt, prompt)</code></pre>
            </div>
        </div>
        <div class="improvement">
            ðŸŽ¯ <span>Improvement:</span> Encapsulating the OpenAI client within a class enhances modularity and readability, making the codebase more maintainable.
        </div>
    </div>

    <div class="step">
        <div class="step-header">
            <h2>Step 3: Separating Cost Calculation Logic</h2>
        </div>
        <div class="explanation">
            Isolating the cost calculation into its own class simplifies the main function and adheres to the Single Responsibility Principle. This separation also facilitates easier testing and potential future modifications to pricing structures.
        </div>
        <div class="code-container">
            <div class="code-block">
                <h3>Original Code Snippet</h3>
                <pre><code class="python"># Measure cost for o1, o1-mini    
if o1_model == "o1":
    input_token_price = 15.00 / 1000000
    cached_input_token_price = 7.50 / 1000000
    output_token_price = 60.00 / 1000000
elif o1_model == "o1-mini":
    input_token_price = 3.00 / 1000000
    cached_input_token_price = 1.50 / 1000000
    output_token_price = 12.00 / 1000000

prompt_tokens = response.usage.prompt_tokens
cached_input_tokens = response.usage.prompt_tokens_details.cached_tokens
output_tokens = response.usage.completion_tokens

# Individual cost
input_token_cost = (prompt_tokens - cached_input_tokens) * input_token_price
cached_input_token_cost = cached_input_tokens * cached_input_token_price
output_token_cost = output_tokens * output_token_price

total_cost = input_token_cost + cached_input_token_cost + output_token_cost</code></pre>
            </div>
            <div class="code-block">
                <h3>Refactored Code Snippet</h3>
                <pre><code class="python">class CostCalculator:
    PRICING = {
        "o1": {
            "input_token_price": 15.00 / 1000000,
            "cached_input_token_price": 7.50 / 1000000,
            "output_token_price": 60.00 / 1000000
        },
        "o1-mini": {
            "input_token_price": 3.00 / 1000000,
            "cached_input_token_price": 1.50 / 1000000,
            "output_token_price": 12.00 / 1000000
        }
    }

    def __init__(self, model: str):
        if model not in self.PRICING:
            raise ValueError(f"Unsupported model type: {model}")
        self.pricing = self.PRICING[model]

    def calculate_total_cost(self, prompt_tokens: int, cached_input_tokens: int, output_tokens: int) -> float:
        input_token_cost = (prompt_tokens - cached_input_tokens) * self.pricing["input_token_price"]
        cached_input_token_cost = cached_input_tokens * self.pricing["cached_input_token_price"]
        output_token_cost = output_tokens * self.pricing["output_token_price"]
        return input_token_cost + cached_input_token_cost + output_token_cost

# Usage within o1_response function
cost_calculator = CostCalculator(o1_model)
total_cost = cost_calculator.calculate_total_cost(
    prompt_tokens=response.usage.prompt_tokens,
    cached_input_tokens=response.usage.prompt_tokens_details.cached_tokens,
    output_tokens=response.usage.completion_tokens
)</code></pre>
            </div>
        </div>
        <div class="improvement">
            ðŸŽ¯ <span>Improvement:</span> Abstracting the cost calculation into its own class promotes reusability and clean code structure, facilitating easier updates to pricing models.
        </div>
    </div>

    <div class="step">
        <div class="step-header">
            <h2>Step 4: Refactoring the Display Logic</h2>
        </div>
        <div class="explanation">
            By moving the display-related code into its own class, we achieve better separation of concerns. This makes the main response generation logic cleaner and focuses each class on a single responsibility.
        </div>
        <div class="code-container">
            <div class="code-block">
                <h3>Original Code Snippet</h3>
                <pre><code class="python">if display:
    # Display the time taken for the response
    display(HTML(f'<div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">                <h2>ðŸ”½ &nbsp; O1 Model Response</h2><p>Response time: {response_time:.2f} seconds</p></div>'))

    # Display the response in a formatted way
    display(Markdown(response_content))
    display(HTML('<div style="background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">                <h2>ðŸ”¼ &nbsp; Markdown End</h2></div>'))</code></pre>
            </div>
            <div class="code-block">
                <h3>Refactored Code Snippet</h3>
                <pre><code class="python">class ResponseDisplay:
    def __init__(self, response_time: float, response_content: str, model: str):
        self.response_time = response_time
        self.response_content = response_content
        self.model = model

    def display_response(self):
        display(HTML(f'''
            <div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
                <h2>ðŸ”½ &nbsp; {self.model.capitalize()} Model Response</h2>
                <p>Response time: {self.response_time:.2f} seconds</p>
            </div>
        '''))

        display(Markdown(self.response_content))
        display(HTML('''
            <div style="background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
                <h2>ðŸ”¼ &nbsp; Markdown End</h2>
            </div>
        '''))

# Usage within o1_response function
if display_flag:
    response_display = ResponseDisplay(response_time, response_content, o1_model)
    response_display.display_response()</code></pre>
            </div>
        </div>
        <div class="improvement">
            ðŸŽ¯ <span>Improvement:</span> Isolating display functionalities into a separate class enhances code readability and maintainability, allowing for easier updates to the presentation logic.
        </div>
    </div>

    <div class="step">
        <div class="step-header">
            <h2>Step 5: Consolidating HTML Generation and File Saving</h2>
        </div>
        <div class="explanation">
            Combining the HTML generation and file saving into a dedicated class streamlines the process of creating and storing the response. This approach enforces modularity and makes the codebase more organized.
        </div>
        <div class="code-container">
            <div class="code-block">
                <h3>Original Code Snippet</h3>
                <pre><code class="python"># Format the response as HTML
html_content = f"""
<html>
<head>
    <meta charset="UTF-8">
    <title>O1 Response</title>
    <!-- Add MathJax for LaTeX rendering -->
    <script type="text/javascript" async 
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
</head>
<body>
<!-- HTML content with system prompt, user prompt, and response -->
</body>
</html>
"""

# Save the HTML content to a file
with open(file_name, "w", encoding="utf-8") as file:
    file.write(html_content)

print(f"Response saved to {file_name}")</code></pre>
            </div>
            <div class="code-block">
                <h3>Refactored Code Snippet</h3>
                <pre><code class="python">class HTMLGenerator:
    TEMPLATE = """
    <html>
    <head>
        <meta charset="UTF-8">
        <title>{model} Response</title>
        <!-- Add MathJax for LaTeX rendering -->
        <script type="text/javascript" async 
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    </head>
    <body>
        <h2>System Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            {system_prompt_html}
        </div>

        <h2>User Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            {prompt_html}
        </div>

        <br><br>
        <div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
            <h2>{model} Model Response</h2>
            <p>Response time: {response_time:.2f} seconds</p>
            <p>Total Cost: {total_cost:.2f} $</p>
        </div>

        <div style="padding: 10px;">
            {response_html}
        </div>
    </body>
    </html>
    """

    def __init__(self, model: str, system_prompt: str, user_prompt: str, response_html: str, response_time: float, total_cost: float):
        self.model = model
        self.system_prompt_html = system_prompt.replace('\n', '<br>')
        self.prompt_html = user_prompt.replace('\n', '<br>')
        self.response_html = response_html
        self.response_time = response_time
        self.total_cost = total_cost

    def generate_html(self) -> str:
        return self.TEMPLATE.format(
            model=self.model,
            system_prompt_html=self.system_prompt_html,
            prompt_html=self.prompt_html,
            response_time=self.response_time,
            total_cost=self.total_cost,
            response_html=self.response_html
        )

    def save_to_file(self, file_name: str):
        html_content = self.generate_html()
        with open(file_name, "w", encoding="utf-8") as file:
            file.write(html_content)
        print(f"Response saved to {file_name}")

# Usage within o1_response function
html_generator = HTMLGenerator(
    model=o1_model,
    system_prompt=system_prompt,
    user_prompt=prompt,
    response_html=markdown.markdown(result['content']),
    response_time=result['time'],
    total_cost=total_cost
)
html_generator.save_to_file(file_name)</code></pre>
            </div>
        </div>
        <div class="improvement">
            ðŸŽ¯ <span>Improvement:</span> Creating an `HTMLGenerator` class encapsulates the HTML creation and file-saving process, promoting code reuse and enhancing clarity.
        </div>
    </div>

    <div class="step">
        <div class="step-header">
            <h2>Step 6: Integrating All Components into a Cohesive OOP Structure</h2>
        </div>
        <div class="explanation">
            After modularizing individual functionalities, we integrate them into a unified class. This comprehensive object-oriented approach ensures that each component interacts seamlessly, resulting in a clean and maintainable codebase.
        </div>
        <div class="code-container">
            <div class="code-block">
                <h3>Original `o1_response` Function</h3>
                <pre><code class="python">def o1_response(prompt, system_prompt, o1_model="o1", display=False, file_name="o1_response_test.html"):
    # [Original procedural code]
    return response</code></pre>
            </div>
            <div class="code-block">
                <h3>Refactored `O1Responder` Class</h3>
                <pre><code class="python">class O1Responder:
    def __init__(self, model: str = "o1", display_flag: bool = False, file_name: str = "o1_response_test.html"):
        self.model = model
        self.display_flag = display_flag
        self.file_name = file_name
        self.openai_client = OpenAIClient(api_key=get_openai_api_key())
        self.cost_calculator = CostCalculator(self.model)

    def generate_response(self, system_prompt: str, user_prompt: str):
        start_time = time.time()
        response = self.openai_client.generate_response(self.model, system_prompt, user_prompt)
        end_time = time.time()
        response_time = end_time - start_time

        total_cost = self.cost_calculator.calculate_total_cost(
            prompt_tokens=response.usage.prompt_tokens,
            cached_input_tokens=response.usage.prompt_tokens_details.cached_tokens,
            output_tokens=response.usage.completion_tokens
        )

        response_content = response.choices[0].message.content

        if self.display_flag:
            response_display = ResponseDisplay(response_time, response_content, self.model)
            response_display.display_response()

        html_generator = HTMLGenerator(
            model=self.model,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_html=markdown.markdown(response_content),
            response_time=response_time,
            total_cost=total_cost
        )
        html_generator.save_to_file(self.file_name)

        print(f"Response saved to {self.file_name}")
        return response

# Usage Example
# responder = O1Responder(model="o1", display_flag=True, file_name="output.html")
# responder.generate_response(system_prompt, user_prompt)</code></pre>
            </div>
        </div>
        <div class="improvement">
            ðŸŽ¯ <span>Improvement:</span> The `O1Responder` class orchestrates all components, providing a clear interface for generating responses. This consolidation enhances code organization and facilitates easier usage.
        </div>
    </div>

    <div class="step">
        <div class="step-header">
            <h2>Final Refactored Codebase</h2>
        </div>
        <div class="explanation">
            Combining all the refactored components, here's the complete object-oriented implementation of the original `o1_response` function. This structure promotes scalability, maintainability, and clarity.
        </div>
        <div class="code-container">
            <div class="code-block">
                <h3>Complete Refactored Code</h3>
                <pre><code class="python">import warnings
import time
from IPython.display import display, Markdown, HTML
from helper import get_openai_api_key
from openai import OpenAI
import markdown

# OpenAI Client Wrapper
class OpenAIClient:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def generate_response(self, model: str, system_prompt: str, user_prompt: str):
        message = {
            "role": "user",
            "content": f"&lt;System Prompt&gt;{system_prompt}&lt;/System Prompt&gt;\n&lt;USER Prompt&gt;{user_prompt}&lt;/USER Prompt&gt;"
        }
        response = self.client.chat.completions.create(
            model=model,
            messages=[message]
        )
        return response

# Cost Calculator
class CostCalculator:
    PRICING = {
        "o1": {
            "input_token_price": 15.00 / 1000000,
            "cached_input_token_price": 7.50 / 1000000,
            "output_token_price": 60.00 / 1000000
        },
        "o1-mini": {
            "input_token_price": 3.00 / 1000000,
            "cached_input_token_price": 1.50 / 1000000,
            "output_token_price": 12.00 / 1000000
        }
    }

    def __init__(self, model: str):
        if model not in self.PRICING:
            raise ValueError(f"Unsupported model type: {model}")
        self.pricing = self.PRICING[model]

    def calculate_total_cost(self, prompt_tokens: int, cached_input_tokens: int, output_tokens: int) -> float:
        input_token_cost = (prompt_tokens - cached_input_tokens) * self.pricing["input_token_price"]
        cached_input_token_cost = cached_input_tokens * self.pricing["cached_input_token_price"]
        output_token_cost = output_tokens * self.pricing["output_token_price"]
        return input_token_cost + cached_input_token_cost + output_token_cost

# Response Display Handler
class ResponseDisplay:
    def __init__(self, response_time: float, response_content: str, model: str):
        self.response_time = response_time
        self.response_content = response_content
        self.model = model

    def display_response(self):
        display(HTML(f'''
            <div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
                <h2>ðŸ”½ &nbsp; {self.model.capitalize()} Model Response</h2>
                <p>Response time: {self.response_time:.2f} seconds</p>
            </div>
        '''))

        display(Markdown(self.response_content))
        display(HTML('''
            <div style="background-color: #fff4f4; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
                <h2>ðŸ”¼ &nbsp; Markdown End</h2>
            </div>
        '''))

# HTML Generator
class HTMLGenerator:
    TEMPLATE = """
    <html>
    <head>
        <meta charset="UTF-8">
        <title>{model} Response</title>
        <!-- Add MathJax for LaTeX rendering -->
        <script type="text/javascript" async 
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    </head>
    <body>
        <h2>System Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            {system_prompt_html}
        </div>

        <h2>User Prompt</h2>
        <div style="background-color: #f0f0f0; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            {prompt_html}
        </div>

        <br><br>
        <div style="background-color: #f0fff8; padding: 10px; border-radius: 5px; border: 1px solid #d3d3d3;">
            <h2>{model} Model Response</h2>
            <p>Response time: {response_time:.2f} seconds</p>
            <p>Total Cost: {total_cost:.2f} $</p>
        </div>

        <div style="padding: 10px;">
            {response_html}
        </div>
    </body>
    </html>
    """

    def __init__(self, model: str, system_prompt: str, user_prompt: str, response_html: str, response_time: float, total_cost: float):
        self.model = model
        self.system_prompt_html = system_prompt.replace('\n', '<br>')
        self.prompt_html = user_prompt.replace('\n', '<br>')
        self.response_html = response_html
        self.response_time = response_time
        self.total_cost = total_cost

    def generate_html(self) -> str:
        return self.TEMPLATE.format(
            model=self.model,
            system_prompt_html=self.system_prompt_html,
            prompt_html=self.prompt_html,
            response_time=self.response_time,
            total_cost=self.total_cost,
            response_html=self.response_html
        )

    def save_to_file(self, file_name: str):
        html_content = self.generate_html()
        with open(file_name, "w", encoding="utf-8") as file:
            file.write(html_content)
        print(f"Response saved to {file_name}")

# Main Responder Class
class O1Responder:
    def __init__(self, model: str = "o1", display_flag: bool = False, file_name: str = "o1_response_test.html"):
        self.model = model
        self.display_flag = display_flag
        self.file_name = file_name
        self.openai_client = OpenAIClient(api_key=get_openai_api_key())
        self.cost_calculator = CostCalculator(self.model)

    def generate_response(self, system_prompt: str, user_prompt: str):
        start_time = time.time()
        response = self.openai_client.generate_response(self.model, system_prompt, user_prompt)
        end_time = time.time()
        response_time = end_time - start_time

        total_cost = self.cost_calculator.calculate_total_cost(
            prompt_tokens=response.usage.prompt_tokens,
            cached_input_tokens=response.usage.prompt_tokens_details.cached_tokens,
            output_tokens=response.usage.completion_tokens
        )

        response_content = response.choices[0].message.content

        if self.display_flag:
            response_display = ResponseDisplay(response_time, response_content, self.model)
            response_display.display_response()

        html_generator = HTMLGenerator(
            model=self.model,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            response_html=markdown.markdown(response_content),
            response_time=response_time,
            total_cost=total_cost
        )
        html_generator.save_to_file(self.file_name)

        print(f"Response saved to {self.file_name}")
        return response

# Usage Example
# responder = O1Responder(model="o1", display_flag=True, file_name="output.html")
# responder.generate_response(system_prompt, user_prompt)</code></pre>
            </div>
        </div>
        <div class="improvement">
            ðŸŽ¯ <span>Improvement:</span> The final object-oriented structure ensures a clear separation of concerns, enhancing scalability and maintainability.
        </div>
    </div>

</body>
</html>
<p>```</p>
        </div>
    </body>
    </html>
    